"""
AI-Sheet-Pro AI ä»£ç†ï¼ˆå¢å¼ºç‰ˆï¼‰
é›†æˆ DeepSeek LLM çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»£ç†
"""

import os
import json
import httpx
import yaml
from pathlib import Path
from typing import Any, Dict, List, Optional
from db_engine import get_engine, DataEngine
from sandbox import get_sandbox, CodeSandbox
from logger import get_logger


# åŠ è½½ Prompt é…ç½®æ–‡ä»¶
def load_prompts():
    """ä»å¤–éƒ¨ YAML æ–‡ä»¶åŠ è½½ç³»ç»Ÿæç¤ºè¯"""
    prompts_path = Path(__file__).parent / "prompts.yaml"
    try:
        with open(prompts_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"Warning: Failed to load prompts.yaml: {e}")
        return {}

_PROMPTS = load_prompts()
SYSTEM_PROMPT = _PROMPTS.get('system_prompt', '')
SEMANTIC_MAPPING_PROMPT = _PROMPTS.get('semantic_mapping_prompt', '')


class LLMClient:
    """LLM å®¢æˆ·ç«¯ - æ”¯æŒ OpenAI å…¼å®¹ API"""
    
    def __init__(self, api_base: str, api_key: str, model: str = "deepseek-chat"):
        self.api_base = api_base.rstrip('/')
        self.api_key = api_key
        self.model = model
        self.client = httpx.Client(timeout=60.0)
    
    def chat(self, messages: List[dict], temperature: float = 0.7) -> str:
        """å‘é€èŠå¤©è¯·æ±‚"""
        url = f"{self.api_base}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": 2000
        }
        
        response = self.client.post(url, headers=headers, json=payload)
        response.raise_for_status()
        
        result = response.json()
        return result["choices"][0]["message"]["content"]


# æ³¨æ„: SYSTEM_PROMPT å’Œ SEMANTIC_MAPPING_PROMPT ç°åœ¨ä» prompts.yaml æ–‡ä»¶åŠ è½½
# è¯·ç¼–è¾‘ server/prompts.yaml æ¥ä¿®æ”¹æç¤ºè¯



class AIAgent:
    """AI ä»£ç† - åŸºäº ReAct æ¶æ„çš„æ™ºèƒ½ä½“"""
    
    def __init__(self):
        self.engine = get_engine()
        self.sandbox = get_sandbox()
        self.config = self._load_config()
        self.llm_client = self._init_llm_client()
        self.conversation_history = []
        self.pending_execution = None  # å¾…ç¡®è®¤æ‰§è¡Œçš„ä»£ç 
    
    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®"""
        config_path = Path(__file__).parent / 'taskweaver_config' / 'taskweaver_config.json'
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _init_llm_client(self) -> Optional[LLMClient]:
        """åˆå§‹åŒ– LLM å®¢æˆ·ç«¯"""
        api_base = self.config.get('llm.api_base', '')
        api_key = self.config.get('llm.api_key', '')
        model = self.config.get('llm.model', 'deepseek-chat')
        
        if api_base and api_key:
            return LLMClient(api_base, api_key, model)
        return None
    
    def get_context(self) -> str:
        """è·å–å½“å‰æ•°æ®ä¸Šä¸‹æ–‡"""
        self.engine.refresh_metadata()
        tables = self.engine.get_all_tables()
        if not tables:
            return "å½“å‰æ²¡æœ‰åŠ è½½ä»»ä½•æ•°æ®è¡¨ã€‚"
        
        context = "## å·²åŠ è½½çš„æ•°æ®è¡¨\n\n"
        for table_name in tables:
            context += self.engine.describe_table(table_name) + "\n---\n"
        return context
    
    def execute_tool(self, action: str, action_input: dict) -> str:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        try:
            if action == 'inspect_data':
                return str(self.engine.inspect_column(
                    action_input.get('table_name'), 
                    action_input.get('column_name'),
                    action_input.get('n', 10)
                ))
                
            elif action == 'execute_python':
                code = action_input.get('code', '')
                try:
                    # é¢„æ£€æŸ¥ä»£ç å®‰å…¨æ€§
                    is_safe, error = self.sandbox.validate_code(code)
                    if not is_safe:
                        return f"Security Error: {error}"
                    
                    # åœ¨æ²™ç®±ä¸­å°è¯•é¢„è¿è¡Œï¼ˆä¸æäº¤äº‹åŠ¡ï¼Œæˆ–ä»…ä½œä¸ºè¯­æ³•æ£€æŸ¥ï¼‰
                    # æ³¨æ„ï¼šä¸ºäº† ReAct è‡ªæ„ˆï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦çœŸæ­£æ‰§è¡Œä¸€æ­¥æ¥çœ‹çœ‹æ˜¯å¦æŠ¥é”™
                    # ä½†å¯¹äº data modificationï¼Œè¿™å¯èƒ½å¯¼è‡´å‰¯ä½œç”¨ã€‚
                    # ReAct çš„ execute_python å·¥å…·åœ¨â€œæ€è€ƒâ€é˜¶æ®µæ˜¯å¦åº”è¯¥çœŸæ­£æ‰§è¡Œï¼Ÿ
                    # ç­–ç•¥ï¼šçœŸæ­£æ‰§è¡Œã€‚å¦‚æœç”¨æˆ·åæ‚”ï¼Œä½¿ç”¨ Undoã€‚
                    
                    # ä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬æ•è·æ‰§è¡Œç»“æœä½†ä¸æŒä¹…åŒ–ï¼ˆé™¤éæ˜¯ finishï¼‰
                    # åœ¨ ReAct ä¸­ï¼Œä¸­é—´æ­¥éª¤çš„ execute_python é€šå¸¸æ˜¯ä¸ºäº†åšè®¡ç®—
                    # å¦‚æœåŒ…å«å†™æ“ä½œï¼ˆDELETE/UPDATEï¼‰ï¼Œåº”è¯¥è­¦å‘Šï¼Ÿ 
                    # ç®€åŒ–èµ·è§ï¼šå…è®¸æ‰§è¡Œã€‚Undo Manager ä¼šåœ¨ confirm_and_execute ä¸­ç»Ÿä¸€å¤„ç† Snapshotï¼Œ
                    # ä½†åœ¨è¿™é‡Œæ˜¯åœ¨ ReAct å¾ªç¯å†…éƒ¨...
                    
                    # æ”¹è¿›ç­–ç•¥ï¼šReAct å†…éƒ¨çš„ execute_python åº”è¯¥åªç”¨äºâ€œæŸ¥çœ‹/è®¡ç®—â€ã€‚
                    # çœŸæ­£çš„å†™æ“ä½œä»£ç ï¼Œåº”è¯¥è¢«ä½œä¸º Final Answer è¿”å›ï¼Œç”± confirm_and_execute ç»Ÿä¸€æ‰§è¡Œã€‚
                    # æˆ–è€…ï¼Œæˆ‘ä»¬å…è®¸ ReAct é€æ­¥æ‰§è¡Œï¼Œä½†æ¯ä¸€æ­¥éƒ½è®°å½•ã€‚
                    
                    # å½“å‰ Prompts å®šä¹‰ï¼šexecute_python ç”¨äºæ¸…æ´—ã€è®¡ç®—ã€‚
                    # æˆ‘ä»¬æš‚æ—¶å°±åœ¨æ²™ç®±è·‘ï¼Œå¦‚æœå‡ºé”™è¿”å› Error ç»™ AIã€‚
                    
                    result = self.sandbox.execute(
                        code,
                        local_vars={},
                        db_connection=self.engine.conn
                    )
                    
                    if not result['success']:
                        return f"Execution Error: {result['error']}"
                    
                    # è¿”å›ç»“æœæ‘˜è¦
                    res_val = result.get('result')
                    if hasattr(res_val, '__len__') and len(str(res_val)) > 500:
                        return f"Result (truncated): {str(res_val)[:500]}..."
                    return str(res_val)
                    
                except Exception as e:
                    return f"Runtime Error: {str(e)}"
                    
            elif action == 'execute_ui_command':
                # UI å‘½ä»¤çœŸæ­£åŠ å…¥é˜Ÿåˆ—
                from ui_commands import get_ui_queue
                get_ui_queue().add(action_input)
                return "UI command queued."
                
            elif action == 'finish':
                return "Task Loop Finished"
                
            else:
                return f"Apps Error: Unknown tool '{action}'"
                
        except Exception as e:
            return f"Tool Error: {str(e)}"

    def run_react_loop(self, query: str) -> Dict[str, Any]:
        """è¿è¡Œ ReAct æ€è€ƒå¾ªç¯"""
        context = self.get_context()
        tables = self.engine.get_all_tables()
        
        if not self.llm_client:
            return self._fallback_generate(query, tables)
            
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": f"## Context\n{context}\n\n## Question\n{query}"}
        ]
        
        max_steps = 5
        final_response = None
        
        # è®°å½• ReAct è½¨è¿¹
        trajectory = []
        
        for step in range(max_steps):
            # 1. LLM æ€è€ƒ
            response_text = self.llm_client.chat(messages, temperature=0.3)
            trajectory.append(f"Step {step+1}: {response_text}")
            get_logger().add_log("REACT_STEP", f"Step {step+1}", details=response_text)
            
            # å°†å›å¤åŠ å…¥å†å²
            messages.append({"role": "assistant", "content": response_text})
            
            # 2. è§£æ Thought/Action
            parsed = self._parse_react_response(response_text)
            
            if not parsed:
                # AI æ²¡æœ‰éµå¾ªæ ¼å¼ï¼Œå¯èƒ½ç›´æ¥ç»™äº†ç­”æ¡ˆï¼Œæˆ–è€…æ ¼å¼é”™äº†
                # å°è¯•å½“ä½œç›´æ¥å›ç­”å¤„ç†
                final_response = {
                    'type': 'mixed',
                    'explanation': response_text, # å¾ˆå¤§å¯èƒ½æ˜¯è§£é‡Š
                    'code': '',
                    'commands': []
                }
                break
                
            if parsed['action'] == 'finish':
                # ä»»åŠ¡å®Œæˆ - ä» AI è¿”å›çš„ç»“æ„åŒ– JSON ä¸­è¯»å–ç±»å‹å’Œç­”æ¡ˆ
                final_input = parsed['action_input']
                # ğŸ†• ç›´æ¥è¯»å– AI æ ‡æ³¨çš„ type å­—æ®µï¼ˆå¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ° answerï¼‰
                ai_response_type = final_input.get('type', 'answer')
                ai_answer = final_input.get('answer', final_input.get('final_answer', ''))
                ai_temp_table = final_input.get('temp_table', None) # ğŸ†• æå–ä¸´æ—¶è¡¨å
                
                final_response = {
                    'response_type': ai_response_type,  # AI è‡ªä¸»æ ‡æ³¨çš„ç±»å‹
                    'explanation': ai_answer,
                    'temp_table': ai_temp_table,        # ğŸ†• ä¼ é€’ä¸´æ—¶è¡¨å
                    'code': '', 
                    'commands': []
                }
                break
            
            # 3. æ‰§è¡Œå·¥å…·
            observation = self.execute_tool(parsed['action'], parsed['action_input'])
            
            # è®°å½•å·¥å…·è°ƒç”¨çš„ä»£ç ï¼ˆå¦‚æœæ˜¯ pythonï¼‰ä»¥ä¾¿åç»­å¯èƒ½çš„é‡æ”¾æˆ–å®¡è®¡
            if parsed['action'] == 'execute_python':
                # è¿™é‡Œæœ‰ä¸€ä¸ªè®¾è®¡é€‰æ‹©ï¼šæ˜¯æŠŠæ‰€æœ‰æ­¥éª¤çš„ä»£ç æ‹¼èµ·æ¥ï¼Œè¿˜æ˜¯åªä¿ç•™æœ€åä¸€æ­¥ï¼Ÿ
                # å¯¹äºæ•°æ®åˆ†æï¼ˆQueryï¼‰ï¼Œæœ€åä¸€æ­¥é€šå¸¸å¤Ÿäº†ã€‚
                # å¯¹äºæ•°æ®å¤„ç†ï¼ˆUpdateï¼‰ï¼Œæ¯ä¸€è¡Œéƒ½é‡è¦ã€‚
                # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰æ‰§è¡ŒæˆåŠŸçš„ä»£ç éƒ½è§†ä¸ºæœ€ç»ˆç»“æœçš„ä¸€éƒ¨åˆ†ã€‚
                if 'Execution Error' not in observation:
                    pass 
                
            # 4. åé¦ˆ Observation
            obs_message = f"Observation: {observation}"
            messages.append({"role": "user", "content": obs_message})
            trajectory.append(obs_message)
            
        # æ„é€ æœ€ç»ˆè¿”å›
        # ç”±äºæˆ‘ä»¬æ˜¯åœ¨ ReAct ä¸­å³æ—¶æ‰§è¡Œäº† Pythonï¼Œæ‰€ä»¥ final_response ä¸­çš„ code å¯èƒ½æ˜¯ç©ºçš„
        # è¿™å¯¹äº confirm_and_execute æ¨¡å¼æ˜¯ä¸ªé—®é¢˜ï¼Œå› ä¸ºé‚£é‡ŒæœŸæœ›çš„æ˜¯â€œå¾…ç¡®è®¤çš„ä»£ç â€
        # 
        # ä¿®æ­£ç­–ç•¥ï¼š
        # å¯¹äº query æ¨¡å¼ï¼ˆai_queryï¼‰ï¼ŒReAct å·²ç»åœ¨è¿‡ç¨‹ä¸­æ‰§è¡Œäº†ï¼Œç»“æœåœ¨ conversation ä¸­ã€‚
        # å¯¹äº preview æ¨¡å¼ï¼ˆai_previewï¼‰ï¼Œæˆ‘ä»¬ä¸åº”è¯¥åœ¨ ReAct ä¸­çœŸæ­£æ‰§è¡Œå†™æ“ä½œ (DELETE/UPDATE)ã€‚
        # 
        # è¿™æ˜¯ä¸€ä¸ªä¸¤éš¾ï¼šReAct éœ€è¦æ‰§è¡Œæ‰èƒ½çœ‹åˆ°ç»“æœï¼ˆObservationï¼‰ï¼Œä½† Preview éœ€è¦å…ˆä¸æ‰§è¡Œã€‚
        # 
        # å¦¥åæ–¹æ¡ˆï¼š
        # ReAct æ¨¡å¼ä¸»è¦ç”¨äºâ€œå¢å¼ºçš„ Query å’Œ Analysisâ€ã€‚
        # å¦‚æœæ¶‰åŠâ€œå†™æ“ä½œâ€ï¼Œæˆ‘ä»¬æŒ‡ç¤º Prompt åœ¨ finish æ—¶è¾“å‡ºæœ€ç»ˆä»£ç ï¼Œè€Œä¸åªæ˜¯åœ¨è¿‡ç¨‹ä¸­æ‰§è¡Œã€‚
        # è¿™é‡Œæˆ‘ä»¬æ”¶é›† ReAct è¿‡ç¨‹ä¸­æ‰§è¡Œè¿‡çš„æ‰€æœ‰ Python ä»£ç å—ã€‚
        
        collected_code = []
        collected_commands = []
        
        # ç®€å•çš„æ­£åˆ™æå–
        import re
        for msg in messages:
            if msg['role'] == 'assistant':
                content = msg['content']
                # æå– Action Input ä¸­çš„ code
                # å‡è®¾æ ¼å¼æ˜¯ strict JSON in Action Input
                action_match = re.search(r'Action Input: (\{.*?\})', content, re.DOTALL)
                if action_match:
                    try:
                        inp = json.loads(action_match.group(1))
                        if 'code' in inp:
                            collected_code.append(inp['code'])
                        if 'action' in inp and inp['action'] in ['setHeaderStyle', 'freezeColumns', 'setConditionalFormat', 'setBorder', 'hideRowsWhere', 'sortByColumn']:
                             collected_commands.append(inp)
                    except:
                        pass
        
        full_code = "\n".join(collected_code)
        explanation = final_response.get('explanation', '') if final_response else "ReAct å¾ªç¯ç»“æŸ"
        
        # ========== ä¼˜å…ˆä½¿ç”¨ AI æ ‡æ³¨çš„å“åº”ç±»å‹ ==========
        # å¦‚æœ AI åœ¨ finish ä¸­æ˜ç¡®æ ‡æ³¨äº† typeï¼Œåˆ™ç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™å›é€€åˆ°åç«¯çŒœæµ‹
        ai_response_type = final_response.get('response_type') if final_response else None
        if ai_response_type:
            response_type = ai_response_type
        else:
            # å›é€€ï¼šä½¿ç”¨åç«¯å…³é”®è¯åˆ†ç±»ï¼ˆå…¼å®¹æ—§ç‰ˆ AI å“åº”ï¼‰
            response_type = self._classify_response_type(explanation, full_code, collected_commands)
        
        return {
            'response_type': response_type,  # ğŸ†• æ ¸å¿ƒï¼šAI è‡ªä¸»æ ‡æ³¨çš„ç±»å‹
            'answer': explanation,           # ç»™ç”¨æˆ·çœ‹çš„æ–‡æœ¬ç­”æ¡ˆ
            'temp_table': final_response.get('temp_table') if final_response else None, # ğŸ†• ä¼ é€’ä¸´æ—¶è¡¨å
            'thinking': trajectory,          # AI æ€è€ƒè¿‡ç¨‹ï¼ˆå¯éšè—ï¼‰
            'code': full_code,
            'commands': collected_commands,
            'llm_used': True,
            # ä¿ç•™æ—§å­—æ®µå…¼å®¹æ€§
            'type': 'mixed',
            'explanation': explanation
        }

    def _classify_response_type(self, explanation: str, code: str, commands: list) -> str:
        """æ™ºèƒ½åˆ†ç±» AI å“åº”ç±»å‹"""
        explanation_lower = explanation.lower() if explanation else ''
        
        # 1. è¿½é—®ç±»ï¼šæ£€æµ‹ç–‘é—®å¥æˆ–è¯·æ±‚æ›´å¤šä¿¡æ¯
        clarify_keywords = ['è¯·é—®', 'è¯·å‘Šè¯‰æˆ‘', 'è¯·æŒ‡å®š', 'è¯·é€‰æ‹©', 'éœ€è¦æ›´å¤šä¿¡æ¯', 'å“ªä¸€åˆ—', 'ä»€ä¹ˆæ¡ä»¶', 'ï¼Ÿ']
        if any(kw in explanation for kw in clarify_keywords):
            return 'clarify'
        
        # 2. é”™è¯¯ç±»ï¼šæ‰§è¡Œå¤±è´¥
        error_keywords = ['å¤±è´¥', 'é”™è¯¯', 'error', 'failed', 'æ— æ³•', 'ä¸å­˜åœ¨', 'æ‰¾ä¸åˆ°']
        if any(kw in explanation_lower for kw in error_keywords):
            return 'error'
        
        # 3. UI å‘½ä»¤ç±»ï¼šæœ‰ UI å‘½ä»¤ä¸”æ— æ•°æ®ä»£ç 
        if commands and not code:
            return 'ui'
        
        # 4. æ•°æ®æ“ä½œç±»ï¼šæœ‰ä»£ç æ‰§è¡Œ
        data_keywords = ['åˆ é™¤', 'æ›´æ–°', 'ä¿®æ”¹', 'æ·»åŠ ', 'æ’å…¥', 'delete', 'update', 'insert', 'alter']
        if code and any(kw in code.lower() for kw in data_keywords):
            return 'data'
        
        # 5. æ··åˆç±»ï¼šåŒæ—¶æœ‰ä»£ç å’Œ UI å‘½ä»¤
        if code and commands:
            return 'mixed'
        
        # 6. é»˜è®¤ï¼šçº¯å›ç­”ç±»
        return 'answer'

    def _parse_react_response(self, text: str) -> Optional[Dict]:
        """è§£æ ReAct æ ¼å¼å“åº”"""
        lines = text.split('\n')
        action = None
        action_input = None
        
        for line in lines:
            line = line.strip()
            if line.startswith('Action:'):
                action = line[len('Action:'):].strip()
            elif line.startswith('Action Input:'):
                input_str = line[len('Action Input:'):].strip()
                try:
                    # å°è¯•ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é”™è¯¯ (å¦‚å•å¼•å·)
                    if input_str.startswith("'") and input_str.endswith("'"):
                         input_str = input_str[1:-1]
                    action_input = json.loads(input_str)
                except:
                    # å¦‚æœ json è·¨è¡Œï¼Œéœ€è¦æ›´å¤æ‚çš„æå–
                    # ç®€å•å›é€€ï¼šå°è¯•æ‰¾æ•´ä¸ªæ–‡æœ¬ä¸­çš„ json å—
                    pass
        
        # å¦‚æœç®€å•è§£æå¤±è´¥ï¼Œå°è¯•å…¨æ–‡æ­£åˆ™
        if not action or not action_input:
            import re
            act_match = re.search(r'Action:\s*(.*)', text)
            if act_match:
                action = act_match.group(1).strip()
            
            inp_match = re.search(r'Action Input:\s*(\{.*?\})', text, re.DOTALL)
            if inp_match:
                try:
                    action_input = json.loads(inp_match.group(1))
                except:
                    pass
        
        if action and action_input is not None:
            return {'action': action, 'action_input': action_input}
        return None

    def generate_code(self, query: str) -> Dict[str, Any]:
        """å…¥å£ï¼šä½¿ç”¨ ReAct å¾ªç¯ç”Ÿæˆä»£ç """
        # æ¥ç®¡åŸæœ‰çš„ generate_code
        return self.run_react_loop(query)

    # ä¿ç•™åŸæœ‰çš„è¾…åŠ©æ–¹æ³• (fallback_generate, etc.) ä»¥é˜²ä¸‡ä¸€
    # ... (çœç•¥ï¼Œä½†å®é™…ä»£ç ä¸­éœ€è¦ä¿ç•™)
    
    def _fallback_generate(self, query: str, tables: List[str]) -> Dict[str, Any]:
        """å›é€€çš„ç®€åŒ–ä»£ç ç”Ÿæˆ"""
        if not tables:
            return {'code': "result = 'è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶'", 'explanation': "æ²¡æœ‰æ£€æµ‹åˆ°å·²åŠ è½½çš„æ•°æ®è¡¨", 'llm_used': False}
        table_name = tables[0]
        return {
            'code': f"result = db.execute('SELECT * FROM \"{table_name}\" LIMIT 100').fetchdf().to_dict('records')",
            'explanation': f"è¿”å›è¡¨ {table_name} çš„å‰ 100 è¡Œæ•°æ®",
            'llm_used': False
        }

    # ... (preview_query, confirm_and_execute, execute_query, find_semantic_mappings ä¿æŒä¸å˜)
    # å®ƒä»¬ä¼šè°ƒç”¨æ–°çš„ generate_code (å³ run_react_loop)
    
    def preview_query(self, query: str) -> Dict[str, Any]:
        # ... (ä¿æŒåŸæ ·ï¼Œæ— éœ€ä¿®æ”¹ï¼Œå› ä¸º generate_code æ¥å£ç­¾åæ²¡å˜)
        generated = self.generate_code(query)
        self.pending_execution = {
            'query': query,
            'type': generated.get('type', 'data'),
            'code': generated.get('code', ''),
            'commands': generated.get('commands', []),
            'explanation': generated['explanation']
        }
        return {
            'query': query,
            'type': generated.get('type', 'data'),
            'generated_code': generated.get('code', ''),
            'commands': generated.get('commands', []),
            'explanation': generated['explanation'],
            'llm_used': generated.get('llm_used', False),
            'requires_confirmation': True,
            'execution_id': id(self.pending_execution)
        }

    def confirm_and_execute(self) -> Dict[str, Any]:
        # ... (ä¿æŒåŸæ ·)
        if not self.pending_execution:
            return {'success': False, 'error': 'æ²¡æœ‰å¾…ç¡®è®¤çš„æ“ä½œ'}
        
        cmd_type = self.pending_execution.get('type', 'data')
        code = self.pending_execution.get('code', '')
        commands = self.pending_execution.get('commands', [])
        explanation = self.pending_execution['explanation']
        query = self.pending_execution['query']
        
        self.pending_execution = None
        result = {'success': True, 'result': None}
        ui_result = {'commands_sent': 0}
        
        # å°±ç®— React è¿‡ç¨‹ä¸­è·‘è¿‡äº†ï¼Œconfirm æ—¶å†è·‘ä¸€æ¬¡ä»¥ç¡®ä¿å‰¯ä½œç”¨ï¼ˆå¦‚ä¿®æ”¹æ•°æ®ï¼‰ç”Ÿæ•ˆï¼Ÿ
        # æˆ–è€…æˆ‘ä»¬è®¤ä¸º React è¿‡ç¨‹ä¸­çš„æ˜¯â€œæ¢ç´¢â€ï¼Œè¿™é‡Œæ˜¯â€œæ­£å¼æ‰§è¡Œâ€ï¼Ÿ
        # åŸºäºä¸Šé¢çš„è®¾è®¡ï¼Œcode æ”¶é›†äº†æ‰€æœ‰æ­¥éª¤ï¼Œæ‰€ä»¥è¿™é‡Œä¼šé‡æ”¾ä¸€éã€‚
        # è¿™å¯¹äºè¯»æ“ä½œæ²¡é—®é¢˜ï¼ˆå¤šè¯»ä¸€æ¬¡ï¼‰ï¼Œå¯¹äºå†™æ“ä½œä¹Ÿæ²¡é—®é¢˜ï¼ˆå¹‚ç­‰æˆ–æ˜¯æˆ‘ä»¬æœŸæœ›çš„ï¼‰ã€‚
        
        if cmd_type in ('data', 'mixed') and code:
            from undo_manager import get_undo_manager
            tables = self.engine.get_all_tables()
            if tables:
                get_undo_manager().create_snapshot(tables)
            result = self.sandbox.execute(code, local_vars={}, db_connection=self.engine.conn)
        
        if cmd_type in ('ui', 'mixed') and commands:
            from ui_commands import get_ui_queue
            get_ui_queue().add_batch(commands)
            ui_result['commands_sent'] = len(commands)
            get_logger().add_log("UI_CMD", f"Queued {len(commands)} UI commands", details=commands)
            
        return {
            'query': query,
            'type': cmd_type,
            'generated_code': code,
            'commands_sent': ui_result['commands_sent'],
            'explanation': explanation,
            'execution_result': result,
            'success': result.get('success', True)
        }

    def execute_query(self, query: str) -> Dict[str, Any]:
        """ç›´æ¥æ‰§è¡ŒæŸ¥è¯¢ï¼ˆè·³è¿‡ç¡®è®¤ï¼‰"""
        generated = self.generate_code(query)
        code = generated.get('code', '')
        
        # å¤„ç†ç©ºä»£ç æƒ…å†µ
        if not code:
            return {
                'query': query,
                'generated_code': '',
                'explanation': generated.get('explanation', ''),
                'execution_result': {'success': True, 'result': None},
                'success': True,
                'llm_used': generated.get('llm_used', False),
                # âœ… ä¼ é€’ AI å“åº”åˆ†ç±»
                'response_type': generated.get('response_type', 'answer'),
                'answer': generated.get('answer', generated.get('explanation', ''))
            }
        
        result = self.sandbox.execute(code, local_vars={}, db_connection=self.engine.conn)
        return {
            'query': query,
            'generated_code': code,
            'explanation': generated.get('explanation', ''),
            'execution_result': result,
            'success': result.get('success', False),
            'llm_used': generated.get('llm_used', False),
            # âœ… ä¼ é€’ AI å“åº”åˆ†ç±»
            'response_type': generated.get('response_type', 'answer'),
            'answer': generated.get('answer', generated.get('explanation', '')),
            'temp_table': generated.get('temp_table') # ğŸ†• ä¼ é€’ temp_table
        }

    def find_semantic_mappings(self, table_a: str, table_b: str) -> Dict[str, Any]:
        # ... (ä¿æŒåŸæ ·ï¼Œæˆ–è€…ä¹Ÿå‡çº§ä¸º ReAct? æš‚æ—¶ä¿æŒåŸæ ·ä»¥é™ä½é£é™©)
        if table_a not in self.engine.tables or table_b not in self.engine.tables:
            return {'error': 'è¡¨ä¸å­˜åœ¨'}
        info_a = self.engine.describe_table(table_a)
        info_b = self.engine.describe_table(table_b)
        
        if not self.llm_client:
             return self._fallback_mapping(table_a, table_b)
             
        prompt = SEMANTIC_MAPPING_PROMPT.format(table_a_info=info_a, table_b_info=info_b)
        messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ•°æ®åˆ†æä¸“å®¶ã€‚"}, {"role": "user", "content": prompt}]
        try:
            response = self.llm_client.chat(messages, temperature=0.2)
            if "```json" in response:
                json_start = response.find("```json") + 7
                json_end = response.find("```", json_start)
                json_str = response[json_start:json_end].strip()
            else:
                json_str = response.strip()
            result = json.loads(json_str)
            result['llm_used'] = True
            return result
        except Exception as e:
            fallback = self._fallback_mapping(table_a, table_b)
            fallback['llm_error'] = str(e)
            return fallback

    def _fallback_mapping(self, table_a: str, table_b: str) -> Dict[str, Any]:
        # ... (ä¿æŒåŸæ ·)
        # ä¸ºäº†èŠ‚çœç¯‡å¹…ï¼Œè¿™é‡Œåº”è¯¥ä¿ç•™åŸæ¥çš„ä»£ç é€»è¾‘
        # å®é™…æ›¿æ¢æ—¶éœ€è¦å°å¿ƒ
        info_a = self.engine.get_table_info(table_a)
        info_b = self.engine.get_table_info(table_b)
        cols_a = info_a[table_a]['column_names']
        cols_b = info_b[table_b]['column_names']
        mappings = []
        for col_a in cols_a:
            for col_b in cols_b:
                if col_a.lower() == col_b.lower():
                    mappings.append({'table_a_col': col_a, 'table_b_col': col_b, 'confidence': 1.0, 'reason': 'åç§°å®Œå…¨åŒ¹é…'})
        return {'mappings': mappings, 'join_key_suggestion': None, 'llm_used': False}


# å…¨å±€å®ä¾‹
_agent_instance: Optional[AIAgent] = None

def get_agent() -> AIAgent:
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = AIAgent()
    return _agent_instance

def reload_agent():
    global _agent_instance
    _agent_instance = AIAgent()
    return _agent_instance

